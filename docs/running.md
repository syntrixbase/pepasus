# ğŸš€ è¿è¡Œ M1ï¼šCLI å¯¹è¯

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•é…ç½®å’Œè¿è¡Œ Pegasus CLI è¿›è¡Œå¯¹è¯ã€‚

## å‰ç½®è¦æ±‚

**é€‰æ‹©ä»¥ä¸‹ä»»ä¸€é€‰é¡¹ï¼š**

1. **äº‘ç«¯ API** â€” OpenAI æˆ– Anthropic API Key
   - OpenAI: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
   - Anthropic: [console.anthropic.com/settings/keys](https://console.anthropic.com/settings/keys)

2. **æœ¬åœ°æ¨¡å‹** â€” Ollamaã€LM Studio ç­‰ï¼ˆæ— éœ€ API keyï¼‰
   - [Ollama](https://ollama.com/) - æ¨èï¼Œæ˜“ç”¨
   - [LM Studio](https://lmstudio.ai/) - GUI ç•Œé¢
   - å…¶ä»– OpenAI-compatible æœåŠ¡

3. Bun è¿è¡Œæ—¶ï¼ˆå·²å®‰è£…ï¼‰

## å¿«é€Ÿå¼€å§‹

### é€‰é¡¹ 1: ä½¿ç”¨ OpenAIï¼ˆæ¨èï¼Œæ€§ä»·æ¯”é«˜ï¼‰

```bash
# 1. å¤åˆ¶é…ç½®æ¨¡æ¿
cp .env.example .env

# 2. ç¼–è¾‘ .env æ–‡ä»¶
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-proj-your-key-here
# LLM_MODEL=gpt-4o-mini

# 3. å¯åŠ¨
bun run dev
```

### é€‰é¡¹ 2: ä½¿ç”¨æœ¬åœ° Ollamaï¼ˆå…è´¹ï¼Œæ— éœ€ API keyï¼‰

```bash
# 1. å®‰è£…å¹¶å¯åŠ¨ Ollama
# macOS/Linux: brew install ollama && ollama serve
# æˆ–è®¿é—® https://ollama.com/download

# 2. æ‹‰å–æ¨¡å‹
ollama pull llama3.2

# 3. é…ç½® .env
# LLM_PROVIDER=openai-compatible
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=llama3.2:latest
# LLM_API_KEY=dummy

# 4. å¯åŠ¨
bun run dev
```

### é€‰é¡¹ 3: ä½¿ç”¨ Anthropic Claude

```bash
# 1. é…ç½® .env
# LLM_PROVIDER=anthropic
# LLM_API_KEY=sk-ant-api03-your-key-here
# LLM_MODEL=claude-sonnet-4-20250514

# 2. å¯åŠ¨
bun run dev
```

ä½ ä¼šçœ‹åˆ°æ¬¢è¿ç•Œé¢ï¼š

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸš€ Pegasus CLI              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Persona: Pegasus (intelligent digital employee)
  Type /help for commands, /exit to quit

>
```

### 3. å¼€å§‹å¯¹è¯

```bash
> ä½ å¥½
  Pegasus: ä½ å¥½ï¼æˆ‘æ˜¯ Pegasusï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ

> å¸®æˆ‘æƒ³ä¸€ä¸ªé¡¹ç›®å
  Pegasus: [æ ¹æ® persona é£æ ¼ç”Ÿæˆå›å¤...]

> /exit
ğŸ‘‹ Goodbye!
```

## å¯ç”¨å‘½ä»¤

| å‘½ä»¤ | è¯´æ˜ |
|------|------|
| `/help` | æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ |
| `/exit` æˆ– `/quit` | é€€å‡º CLI |

## é…ç½®è¯´æ˜

### é»˜è®¤é…ç½®ï¼ˆå¼€ç®±å³ç”¨ï¼‰

ä»¥ä¸‹é…ç½®æœ‰åˆç†çš„é»˜è®¤å€¼ï¼Œæ— éœ€åœ¨ `.env` ä¸­è®¾ç½®ï¼š

| é…ç½®é¡¹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `LLM_PROVIDER` | `openai` | LLM æä¾›å•† |
| `LLM_MODEL` | `gpt-4o-mini` | é»˜è®¤æ¨¡å‹ï¼ˆæ€§ä»·æ¯”é«˜ï¼‰ |
| `IDENTITY_PERSONA_PATH` | `data/personas/default.json` | é»˜è®¤äººæ ¼é…ç½® |
| `AGENT_MAX_ACTIVE_TASKS` | `5` | æœ€å¤§å¹¶å‘ä»»åŠ¡æ•° |
| `PEGASUS_LOG_LEVEL` | `info` | æ—¥å¿—çº§åˆ« |

### æ”¯æŒçš„ LLM Providers

| Provider | é…ç½® | è¯´æ˜ |
|----------|------|------|
| **OpenAI** | `LLM_PROVIDER=openai` | GPT-4o, GPT-4o-mini ç­‰ |
| **Anthropic** | `LLM_PROVIDER=anthropic` | Claude Sonnet 4, Opus 4 ç­‰ |
| **Ollama** | `LLM_PROVIDER=openai-compatible`<br>`LLM_BASE_URL=http://localhost:11434/v1` | æœ¬åœ°è¿è¡Œï¼Œå…è´¹ |
| **LM Studio** | `LLM_PROVIDER=openai-compatible`<br>`LLM_BASE_URL=http://localhost:1234/v1` | æœ¬åœ°è¿è¡Œï¼ŒGUI ç•Œé¢ |
| **Together AI** | `LLM_PROVIDER=openai-compatible`<br>`LLM_BASE_URL=https://api.together.xyz/v1` | å¼€æºæ¨¡å‹æ‰˜ç®¡ |
| **ä»»ä½• OpenAI-compatible** | `LLM_PROVIDER=openai-compatible`<br>`LLM_BASE_URL=your-url` | vLLM, FastChat ç­‰ |

### è‡ªå®šä¹‰é…ç½®

ç¼–è¾‘ `.env` æ–‡ä»¶è‡ªå®šä¹‰é…ç½®ï¼š

```bash
# ä½¿ç”¨æ›´å¼ºå¤§çš„ OpenAI æ¨¡å‹
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o
LLM_API_KEY=sk-proj-...

# ä½¿ç”¨ Claude Opusï¼ˆæœ€å¼ºä½†æœ€è´µï¼‰
LLM_PROVIDER=anthropic
LLM_MODEL=claude-opus-4-20250514
LLM_API_KEY=sk-ant-...

# ä½¿ç”¨æœ¬åœ° Ollamaï¼ˆå…è´¹ï¼‰
LLM_PROVIDER=openai-compatible
LLM_BASE_URL=http://localhost:11434/v1
LLM_MODEL=qwen2.5:latest
LLM_API_KEY=dummy

# ä½¿ç”¨è‡ªå®šä¹‰ persona
IDENTITY_PERSONA_PATH=data/personas/my-custom.json

# è°ƒè¯•æ¨¡å¼ï¼ˆæ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ï¼‰
PEGASUS_LOG_LEVEL=debug
```

### è‡ªå®šä¹‰ Persona

åˆ›å»ºè‡ªå·±çš„ persona é…ç½®æ–‡ä»¶ï¼š

```json
// data/personas/my-assistant.json
{
  "name": "Alice",
  "role": "helpful assistant",
  "personality": ["friendly", "patient", "detail-oriented"],
  "style": "Professional yet warm. Uses clear examples.",
  "values": ["accuracy", "clarity", "empathy"],
  "background": "Alice is designed to help users with technical questions."
}
```

ç„¶ååœ¨ `.env` ä¸­å¼•ç”¨ï¼š

```bash
IDENTITY_PERSONA_PATH=data/personas/my-assistant.json
```

## æ•…éšœæ’é™¤

### é—®é¢˜ï¼šCLI å¡ä½ä¸å“åº”

**åŸå› **ï¼šå¯èƒ½åœ¨ç­‰å¾… LLM å“åº”æˆ–é‡åˆ°ç½‘ç»œé—®é¢˜ã€‚

**è§£å†³**ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. éªŒè¯ API key æ˜¯å¦æœ‰æ•ˆ
3. æŸ¥çœ‹æ—¥å¿—è¾“å‡ºï¼ˆè®¾ç½® `PEGASUS_LOG_LEVEL=debug`ï¼‰
4. æŒ‰ `Ctrl+C` ä¸­æ–­ï¼Œé‡æ–°å¯åŠ¨

### é—®é¢˜ï¼šAPI Key æœªè®¾ç½®

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: API key is required for provider: openai
```

**è§£å†³**ï¼š
```bash
# ç¡®ä¿ .env æ–‡ä»¶å­˜åœ¨ä¸”åŒ…å« API key
cat .env | grep LLM_API_KEY

# å¦‚æœæ²¡æœ‰ï¼Œåˆ›å»º .env æ–‡ä»¶
cat > .env << EOF
LLM_PROVIDER=openai
LLM_API_KEY=your-key-here
LLM_MODEL=gpt-4o-mini
EOF
```

**ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ— éœ€ API key**ï¼š
```bash
# Ollama é…ç½®ï¼ˆæ— éœ€çœŸå® API keyï¼‰
cat > .env << EOF
LLM_PROVIDER=openai-compatible
LLM_BASE_URL=http://localhost:11434/v1
LLM_MODEL=llama3.2:latest
LLM_API_KEY=dummy
EOF
```

### é—®é¢˜ï¼š`data/personas/default.json` ä¸å­˜åœ¨

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: ENOENT: no such file or directory
```

**è§£å†³**ï¼š
è¿™ä¸ªæ–‡ä»¶åº”è¯¥åœ¨ç‰ˆæœ¬æ§åˆ¶ä¸­ã€‚å¦‚æœç¼ºå¤±ï¼Œæ£€æŸ¥ git çŠ¶æ€ï¼š

```bash
git status data/personas/
```

### é—®é¢˜ï¼šAPI é…é¢ä¸è¶³

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: Rate limit exceeded
```

**è§£å†³**ï¼š
1. æ£€æŸ¥ [Anthropic Console](https://console.anthropic.com/settings/limits) é…é¢
2. å‡çº§è®¡åˆ’æˆ–ç­‰å¾…é…é¢é‡ç½®
3. ä¸´æ—¶ä½¿ç”¨ GPTï¼ˆéœ€è¦å®ç° OpenAI providerï¼‰

## æµ‹è¯•éªŒè¯

### éªŒè¯é…ç½®åŠ è½½

```bash
# è¿è¡Œé…ç½®æµ‹è¯•
bun test tests/unit/infra.test.ts
```

### éªŒè¯ Persona åŠ è½½

```bash
# è¿è¡Œèº«ä»½ç³»ç»Ÿæµ‹è¯•
bun test tests/unit/identity.test.ts
```

### éªŒè¯å®Œæ•´æµç¨‹

```bash
# è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆä¸éœ€è¦çœŸå® API keyï¼‰
bun test tests/integration/agent-lifecycle.test.ts
```

## æ¶æ„è¯´æ˜

CLI çš„æ‰§è¡Œæµç¨‹ï¼š

```
startCLI()
  â†“
1. åŠ è½½é…ç½® (getSettings())
2. åŠ è½½ persona (loadPersona())
3. åˆ›å»º LLM model (createAnthropic())
4. åˆ›å»º Agent({ model, persona })
5. å¯åŠ¨ Agent (agent.start())
  â†“
ç”¨æˆ·è¾“å…¥ â†’ agent.submit(text) â†’ TaskFSM è®¤çŸ¥å¾ªç¯
  â†“
REASONING â†’ ACTING â†’ REFLECTING
  â†“
agent.waitForTask(id) â†’ æå– response â†’ æ˜¾ç¤ºç»™ç”¨æˆ·
```

## ä¸‹ä¸€æ­¥

- **M4: ä¼šæ€è€ƒ** â€” å¢å¼ºå¤æ‚ä»»åŠ¡åˆ†è§£èƒ½åŠ›
- **M5: èƒ½å¹¶å‘** â€” å¤šä»»åŠ¡å¹¶å‘å¤„ç†éªŒè¯

## ç›¸å…³æ–‡æ¡£

- [Architecture](./architecture.md) - ç³»ç»Ÿæ¶æ„æ€»è§ˆ
- [Memory System](./memory-system.md) - é•¿æœŸè®°å¿†è®¾è®¡
- [Cognitive Processors](./cognitive.md) - è®¤çŸ¥å¤„ç†å™¨
