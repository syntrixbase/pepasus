# Pegasus Configuration Guide

Pegasus æ”¯æŒä¸¤ç§é…ç½®æ–¹å¼ï¼š**é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰**å’Œ**ç¯å¢ƒå˜é‡**ã€‚

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰

```bash
# 1. ç¼–è¾‘é»˜è®¤é…ç½®æ–‡ä»¶
vim config.yml
# ä¿®æ”¹ provider å’Œå¯¹åº”çš„ apiKeyï¼ˆå¯é€‰ï¼‰

# 2. ï¼ˆæ¨èï¼‰åˆ›å»ºæœ¬åœ°è¦†ç›–é…ç½®
cp config.yml config.local.yml
# ç¼–è¾‘ config.local.ymlï¼Œåªä¿ç•™éœ€è¦è¦†ç›–çš„å­—æ®µ

# 3. è¿è¡Œ
bun run dev
```

**æç¤º**: `config.yml` æ˜¯é¡¹ç›®é»˜è®¤é…ç½®,ä¼šæäº¤åˆ° gitã€‚`config.local.yml` ç”¨äºæœ¬åœ°è¦†ç›–,ä¸ä¼šæäº¤åˆ° gitã€‚

### æ–¹å¼ 2: ç¯å¢ƒå˜é‡

```bash
# ä»ç„¶æ”¯æŒ .env æ–‡ä»¶
cp .env.example .env
# ç¼–è¾‘ .env
bun run dev
```

## ğŸ“‹ é…ç½®æ–‡ä»¶æ ¼å¼

### config.yml ç»“æ„

```yaml
llm:
  provider: openai  # openai | anthropic | openai-compatible

  providers:
    openai:
      apiKey: ${OPENAI_API_KEY}
      model: gpt-4o-mini
      baseURL: null  # Optional: override API endpoint

    anthropic:
      apiKey: ${ANTHROPIC_API_KEY}
      model: claude-sonnet-4-20250514
      baseURL: null

    # For Ollama, LM Studio, etc.
    ollama:
      apiKey: dummy  # Most local models don't need a real key
      model: llama3.2:latest
      baseURL: http://localhost:11434/v1

  maxConcurrentCalls: 3
  timeout: 120  # seconds

agent:
  maxActiveTasks: 5
  maxConcurrentTools: 3
  maxCognitiveIterations: 10
  heartbeatInterval: 60

memory:
  dbPath: data/memory.db
  vectorDbPath: data/vectors

identity:
  personaPath: data/personas/default.json

system:
  logLevel: info  # debug | info | warn | error | silent
  dataDir: data
  logConsoleEnabled: false  # Enable console logging (default: false)
  logFormat: json  # Log format: json | pretty (default: json)
```

### é…ç½®æ–‡ä»¶æŸ¥æ‰¾ç­–ç•¥

Pegasus é‡‡ç”¨**åˆ†å±‚é…ç½®**æ¨¡å¼ï¼š

1. **PEGASUS_CONFIG ç¯å¢ƒå˜é‡**ï¼ˆå¦‚æœè®¾ç½®ï¼‰
2. **config.yml** (é»˜è®¤é…ç½®) â†’ **config.local.yml** (æœ¬åœ°è¦†ç›–,æ·±åº¦åˆå¹¶)
3. **config.yaml** â†’ **config.local.yaml** (å¤‡é€‰,æ·±åº¦åˆå¹¶)
4. å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œå›é€€åˆ°**ç¯å¢ƒå˜é‡æ¨¡å¼**

**æ¨èä½¿ç”¨ `.yml` æ‰©å±•å** (é¡¹ç›®é»˜è®¤ä½¿ç”¨ config.yml)

**é‡è¦**: ä¸èƒ½åŒæ—¶å­˜åœ¨ `config.yaml` å’Œ `config.yml`ï¼Œä¹Ÿä¸èƒ½åŒæ—¶å­˜åœ¨ `config.local.yaml` å’Œ `config.local.yml`ã€‚å¦‚æœæ£€æµ‹åˆ°å†²çªï¼Œç³»ç»Ÿä¼šæŠ›å‡ºé”™è¯¯æç¤ºä½ åˆ é™¤å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶ã€‚

```bash
# âŒ é”™è¯¯ç¤ºä¾‹ - ä¼šæŠ›å‡ºé”™è¯¯
$ ls config*
config.yaml  config.yml  # å†²çªï¼

# âœ… æ­£ç¡®ç¤ºä¾‹ - æ¨èä½¿ç”¨ .yml
$ ls config*
config.yml  config.local.yml  # æ­£ç¡®ï¼ˆæ¨èï¼‰

# âœ… ä¹Ÿå¯ä»¥ä½¿ç”¨ .yaml
$ ls config*
config.yaml  config.local.yaml  # æ­£ç¡®ï¼ˆå¤‡é€‰ï¼‰
```

#### æ·±åº¦åˆå¹¶ç¤ºä¾‹

**config.yml** (åŸºç¡€é…ç½®):
```yaml
llm:
  provider: openai
  providers:
    openai:
      model: gpt-4o-mini
      apiKey: ${OPENAI_API_KEY}
      baseURL: https://api.openai.com/v1
  timeout: 120
memory:
  dbPath: data/memory.db
```

**config.local.yml** (æœ¬åœ°è¦†ç›–):
```yaml
llm:
  provider: anthropic  # è¦†ç›– provider
  providers:
    anthropic:
      model: claude-sonnet-4  # æ·»åŠ æ–°é…ç½®
      apiKey: ${ANTHROPIC_API_KEY}
  timeout: 180  # è¦†ç›– timeout
```

**æœ€ç»ˆç”Ÿæ•ˆé…ç½®**:
```yaml
llm:
  provider: anthropic  # â† æ¥è‡ª local
  providers:
    openai:  # â† æ¥è‡ª baseï¼ˆä¿ç•™ï¼‰
      model: gpt-4o-mini
      apiKey: ${OPENAI_API_KEY}
      baseURL: https://api.openai.com/v1
    anthropic:  # â† æ¥è‡ª local
      model: claude-sonnet-4
      apiKey: ${ANTHROPIC_API_KEY}
  timeout: 180  # â† æ¥è‡ª local
memory:  # â† æ¥è‡ª baseï¼ˆæœªè¦†ç›–ï¼‰
  dbPath: data/memory.db
```

## ğŸ”‘ ç¯å¢ƒå˜é‡æ’å€¼

é…ç½®æ–‡ä»¶æ”¯æŒ `${VAR_NAME}` è¯­æ³•å¼•ç”¨ç¯å¢ƒå˜é‡ï¼Œå¹¶æ”¯æŒ bash é£æ ¼çš„é»˜è®¤å€¼è¯­æ³•ï¼š

### åŸºç¡€è¯­æ³•

```yaml
llm:
  providers:
    openai:
      apiKey: ${OPENAI_API_KEY}  # å¼•ç”¨ç¯å¢ƒå˜é‡
```

### Bash é£æ ¼é»˜è®¤å€¼è¯­æ³•

é…ç½®æ–‡ä»¶æ”¯æŒä»¥ä¸‹ bash é£æ ¼çš„è¯­æ³•ï¼š

#### 1. `${VAR:-default}` - ä½¿ç”¨é»˜è®¤å€¼

å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼š

```yaml
llm:
  providers:
    openai:
      apiKey: ${OPENAI_API_KEY:-sk-default-key}
      model: ${OPENAI_MODEL:-gpt-4o-mini}
```

#### 2. `${VAR:=default}` - è®¾ç½®å¹¶ä½¿ç”¨é»˜è®¤å€¼

å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼å¹¶è®¾ç½®åˆ°ç¯å¢ƒå˜é‡ï¼š

```yaml
llm:
  providers:
    openai:
      model: ${OPENAI_MODEL:=gpt-4o-mini}
```

#### 3. `${VAR:?error}` - å¿…éœ€çš„ç¯å¢ƒå˜é‡

å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–ä¸ºç©ºï¼ŒæŠ›å‡ºé”™è¯¯ï¼š

```yaml
llm:
  providers:
    openai:
      apiKey: ${OPENAI_API_KEY:?API key is required}
```

#### 4. `${VAR:+alternate}` - å·²è®¾ç½®æ—¶ä½¿ç”¨æ›¿ä»£å€¼

å¦‚æœç¯å¢ƒå˜é‡å·²è®¾ç½®ï¼Œä½¿ç”¨æ›¿ä»£å€¼ï¼š

```yaml
llm:
  providers:
    openai:
      baseURL: ${USE_PROXY:+https://proxy.example.com/v1}
```

### å®é™…ä½¿ç”¨ç¤ºä¾‹

```yaml
llm:
  provider: ${LLM_PROVIDER:-openai}

  providers:
    openai:
      # å¿…éœ€çš„ API keyï¼Œæœªè®¾ç½®æ—¶æŠ¥é”™
      apiKey: ${OPENAI_API_KEY:?OpenAI API key is required}
      # å¯é€‰çš„æ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨ gpt-4o-mini
      model: ${OPENAI_MODEL:-gpt-4o-mini}
      # å¯é€‰çš„ä»£ç†ï¼Œè®¾ç½® USE_PROXY æ—¶æ‰å¯ç”¨
      baseURL: ${USE_PROXY:+https://proxy.example.com/v1}

    anthropic:
      apiKey: ${ANTHROPIC_API_KEY}
      model: ${ANTHROPIC_MODEL:-claude-sonnet-4-20250514}

system:
  logLevel: ${LOG_LEVEL:-info}
```

### ä¼˜åŠ¿

è¿™æ ·ä½ å¯ä»¥ï¼š
- é…ç½®æ–‡ä»¶æäº¤åˆ° gitï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰
- æ•æ„Ÿä¿¡æ¯é€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥
- ä¸ºå¼€å‘ç¯å¢ƒæä¾›åˆç†çš„é»˜è®¤å€¼
- å¼ºåˆ¶è¦æ±‚æŸäº›å…³é”®é…ç½®å¿…é¡»è®¾ç½®

## ğŸ“Š é…ç½®ä¼˜å…ˆçº§

ä»é«˜åˆ°ä½ï¼š

1. **ç¯å¢ƒå˜é‡** ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
   - `LLM_PROVIDER=anthropic` è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰è®¾ç½®

2. **config.local.yml**
   - æœ¬åœ°è¦†ç›–é…ç½®ï¼ˆä¸æäº¤ gitï¼‰

3. **config.yml**
   - åŸºç¡€é…ç½®ï¼ˆæäº¤ gitï¼‰

4. **é»˜è®¤å€¼**
   - Schema ä¸­å®šä¹‰çš„é»˜è®¤å€¼

### ç¤ºä¾‹

**config.yml**:
```yaml
llm:
  provider: openai
  providers:
    openai:
      model: gpt-4o-mini
```

**config.local.yml**:
```yaml
llm:
  providers:
    openai:
      model: gpt-4o  # è¦†ç›–ä¸º gpt-4o
```

```bash
# ç¯å¢ƒå˜é‡è¦†ç›–ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
export LLM_PROVIDER=anthropic
export ANTHROPIC_MODEL=claude-opus-4-20250514

bun run dev
# â†’ ä½¿ç”¨ anthropic provider + claude-opus-4-20250514
```

## ğŸ¨ é…ç½®ç¤ºä¾‹

### ç¤ºä¾‹ 1: å¼€å‘ç¯å¢ƒï¼ˆå¤š providerï¼‰

**config.yml** (å›¢é˜Ÿå…±äº«,æäº¤åˆ° git):
```yaml
llm:
  provider: openai
  providers:
    openai:
      apiKey: ${OPENAI_API_KEY}
      model: gpt-4o-mini
    anthropic:
      apiKey: ${ANTHROPIC_API_KEY}
      model: claude-sonnet-4-20250514
    ollama:
      model: llama3.2:latest
      baseURL: http://localhost:11434/v1
  maxConcurrentCalls: 3
```

**config.local.yml** (ä¸ªäººæœ¬åœ°,ä¸æäº¤ git):
```yaml
# æœ¬åœ°å¼€å‘æ—¶ä½¿ç”¨ Ollama
llm:
  provider: ollama
```

åˆ‡æ¢ providerï¼š
```bash
# ä¸´æ—¶æµ‹è¯• Anthropic
export LLM_PROVIDER=anthropic
bun run dev
```

### ç¤ºä¾‹ 2: ç”Ÿäº§ç¯å¢ƒ

**config.yml**:
```yaml
llm:
  provider: anthropic
  providers:
    anthropic:
      apiKey: ${ANTHROPIC_API_KEY}
      model: claude-sonnet-4-20250514
  maxConcurrentCalls: 10
  timeout: 180

agent:
  maxActiveTasks: 20
  maxConcurrentTools: 5

system:
  logLevel: warn
```

### ç¤ºä¾‹ 3: æœ¬åœ°å¼€å‘ï¼ˆOllamaï¼‰

**config.local.yml**:
```yaml
llm:
  provider: ollama
  providers:
    ollama:
      apiKey: dummy
      model: qwen2.5:latest
      baseURL: http://localhost:11434/v1

system:
  logLevel: debug
```

### ç¤ºä¾‹ 4: OpenAI ä»£ç†

**config.yml**:
```yaml
llm:
  provider: openai
  providers:
    openai:
      apiKey: ${OPENAI_API_KEY}
      model: gpt-4o
      baseURL: https://your-proxy.com/v1
```

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

**åˆ†å±‚é…ç½® + ç¯å¢ƒå˜é‡åˆ†ç¦»**ï¼š

**config.yml** (å¯ä»¥æäº¤ git):
```yaml
llm:
  provider: openai
  providers:
    openai:
      apiKey: ${OPENAI_API_KEY}  # å¼•ç”¨ç¯å¢ƒå˜é‡
      model: gpt-4o-mini
```

**config.local.yml** (ä¸æäº¤ git):
```yaml
# æœ¬åœ°å¼€å‘é…ç½®
llm:
  provider: ollama  # è¦†ç›–ä¸ºæœ¬åœ°æ¨¡å‹
```

**.env** (ä¸æäº¤ git):
```bash
OPENAI_API_KEY=sk-proj-actual-key-here
```

### âŒ ä¸æ¨è

```yaml
# ä¸è¦åœ¨é…ç½®æ–‡ä»¶ä¸­ç¡¬ç¼–ç  API key
llm:
  providers:
    openai:
      apiKey: sk-proj-hardcoded-key  # âŒ ä¸è¦è¿™æ ·åš
```

## ğŸ“– å®Œæ•´é…ç½®é€‰é¡¹

### LLM é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `llm.provider` | string | `"openai"` | æ´»è·ƒçš„ provider |
| `llm.providers.<name>.apiKey` | string | - | API keyï¼ˆæ”¯æŒæ’å€¼ï¼‰ |
| `llm.providers.<name>.model` | string | - | æ¨¡å‹åç§° |
| `llm.providers.<name>.baseURL` | string | null | è‡ªå®šä¹‰ API endpoint |
| `llm.maxConcurrentCalls` | number | 3 | æœ€å¤§å¹¶å‘è°ƒç”¨æ•° |
| `llm.timeout` | number | 120 | è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ |

### Agent é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `agent.maxActiveTasks` | number | 5 | æœ€å¤§æ´»è·ƒä»»åŠ¡æ•° |
| `agent.maxConcurrentTools` | number | 3 | æœ€å¤§å¹¶å‘å·¥å…·è°ƒç”¨ |
| `agent.maxCognitiveIterations` | number | 10 | æœ€å¤§è®¤çŸ¥å¾ªç¯æ¬¡æ•° |
| `agent.heartbeatInterval` | number | 60 | å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰ |

### Identity é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `identity.personaPath` | string | `"data/personas/default.json"` | Persona æ–‡ä»¶è·¯å¾„ |

### Memory é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `memory.dbPath` | string | `"data/memory.db"` | SQLite æ•°æ®åº“è·¯å¾„ |
| `memory.vectorDbPath` | string | `"data/vectors"` | å‘é‡æ•°æ®åº“è·¯å¾„ |

### System é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `system.logLevel` | string | `"info"` | æ—¥å¿—çº§åˆ« (debug/info/warn/error/silent) |
| `system.dataDir` | string | `"data"` | æ•°æ®ç›®å½• |
| `system.logConsoleEnabled` | boolean | `false` | å¯ç”¨æ§åˆ¶å°æ—¥å¿—è¾“å‡º (ç›®çš„åœ°) |
| `system.logFormat` | string | `"json"` | æ—¥å¿—è¾“å‡ºæ ¼å¼: `json` æˆ– `pretty` (æ ¼å¼) |

**æ³¨æ„**:
- æ–‡ä»¶æ—¥å¿—æ°¸è¿œå¯ç”¨ï¼Œä¿å­˜åˆ° `{dataDir}/logs/pegasus.log`ï¼Œæ— æ³•ç¦ç”¨
- `logConsoleEnabled` æ§åˆ¶æ—¥å¿—**è¾“å‡ºä½ç½®** (ç›®çš„åœ°)
- `logFormat` æ§åˆ¶æ—¥å¿—**è¾“å‡ºæ ¼å¼** (æ ¼å¼)ï¼ŒåŒæ—¶ä½œç”¨äº file å’Œ console

## ğŸ“ æ—¥å¿—é…ç½®

Pegasus çš„æ—¥å¿—ç³»ç»Ÿæ°¸è¿œå°†æ—¥å¿—å†™å…¥æ–‡ä»¶ï¼Œå¹¶æ”¯æŒå¯é€‰çš„æ§åˆ¶å°è¾“å‡ºã€‚

### é»˜è®¤è¡Œä¸º

- âœ… **æ–‡ä»¶æ—¥å¿—**: æ°¸è¿œå¯ç”¨ï¼Œæ— æ³•ç¦ç”¨ï¼Œä¿å­˜åˆ° `{dataDir}/logs/pegasus.log`
- âŒ **æ§åˆ¶å°æ—¥å¿—**: é»˜è®¤ç¦ç”¨ï¼Œå¯ä»¥æŒ‰éœ€å¯ç”¨

### å¯ç”¨æ§åˆ¶å°è¾“å‡º

**config.yml**:
```yaml
system:
  logLevel: info
  dataDir: data
  # å¯ç”¨æ§åˆ¶å°è¾“å‡ºï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰
  logConsoleEnabled: true
  # ä½¿ç”¨ pretty æ ¼å¼æ›´æ–¹ä¾¿é˜…è¯»
  logFormat: pretty
```

**æˆ–é€šè¿‡ç¯å¢ƒå˜é‡**:
```bash
export PEGASUS_LOG_CONSOLE_ENABLED=true  # å¯ç”¨æ§åˆ¶å°æ—¥å¿—
export PEGASUS_LOG_FORMAT=pretty          # ä½¿ç”¨ pretty æ ¼å¼
```

### æ—¥å¿—ç‰¹æ€§

- **æ¯æ—¥è½®è½¬**: æ¯å¤©è‡ªåŠ¨åˆ›å»ºæ–°çš„æ—¥å¿—æ–‡ä»¶ï¼ˆæ ¼å¼ï¼š`pegasus.log.YYYY-MM-DD`ï¼‰
- **å¤§å°è½®è½¬**: å½“æ—¥å¿—æ–‡ä»¶è¶…è¿‡ 10MB æ—¶è‡ªåŠ¨è½®è½¬
- **è‡ªåŠ¨æ¸…ç†**: è‡ªåŠ¨åˆ é™¤ 30 å¤©å‰çš„æ—§æ—¥å¿—æ–‡ä»¶
- **è‡ªåŠ¨åˆ›å»ºç›®å½•**: å¦‚æœæ—¥å¿—ç›®å½•ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨åˆ›å»º

### æ—¥å¿—æ ¼å¼

æ—¥å¿—ç³»ç»Ÿå°†**è¾“å‡ºä½ç½®**å’Œ**è¾“å‡ºæ ¼å¼**ä½œä¸ºä¸¤ä¸ªç‹¬ç«‹é…ç½®ï¼š

- **`logConsoleEnabled`**: æ§åˆ¶æ—¥å¿—è¾“å‡ºåˆ°å“ªé‡Œï¼ˆç›®çš„åœ°ï¼‰
- **`logFormat`**: æ§åˆ¶æ—¥å¿—çš„æ ¼å¼ï¼ˆjson æˆ– prettyï¼‰ï¼ŒåŒæ—¶ä½œç”¨äº file å’Œ console

| æ ¼å¼ | è¯´æ˜ |
|------|------|
| `json` (é»˜è®¤) | ç»“æ„åŒ– JSON è¡Œï¼Œé€‚åˆæœºå™¨è§£æå’Œæ—¥å¿—èšåˆ |
| `pretty` | å½©è‰²äººç±»å¯è¯»æ ¼å¼ï¼ˆvia pino-prettyï¼‰ï¼Œé€‚åˆå¼€å‘è°ƒè¯• |

- **æ–‡ä»¶è¾“å‡º**: å§‹ç»ˆå¯ç”¨
- **æ§åˆ¶å°è¾“å‡º**: æŒ‰éœ€å¯ç”¨

### ç¤ºä¾‹é…ç½®

**å¼€å‘ç¯å¢ƒï¼ˆæ–‡ä»¶ + æ§åˆ¶å°ï¼‰**:
```yaml
system:
  logLevel: debug
  dataDir: data
  logConsoleEnabled: true   # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
  logFormat: pretty          # ä½¿ç”¨ pretty æ ¼å¼æ–¹ä¾¿é˜…è¯»
```

**ç”Ÿäº§ç¯å¢ƒï¼ˆä»…æ–‡ä»¶ï¼‰**:
```yaml
system:
  logLevel: info
  dataDir: /var/lib/pegasus
  # ä»…æ–‡ä»¶æ—¥å¿—ï¼Œæ— æ§åˆ¶å°è¾“å‡ºï¼ˆé»˜è®¤ï¼‰
  logFormat: json  # JSON æ ¼å¼ä¾›æ—¥å¿—èšåˆç³»ç»Ÿè§£æ
```

æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [æ—¥å¿—æ–‡æ¡£](./logging.md)ã€‚

## ğŸ”„ è¿ç§»æŒ‡å—

### ä»ç¯å¢ƒå˜é‡è¿ç§»åˆ°é…ç½®æ–‡ä»¶

**ä¹‹å‰ï¼ˆ.envï¼‰**ï¼š
```bash
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o-mini
```

**ç°åœ¨ï¼ˆconfig.yml + .envï¼‰**ï¼š

**config.yml**:
```yaml
llm:
  provider: openai
  providers:
    openai:
      apiKey: ${OPENAI_API_KEY}
      model: gpt-4o-mini
```

**.env**:
```bash
OPENAI_API_KEY=sk-proj-...
```

**ä¼˜åŠ¿**ï¼š
- é…ç½®æ–‡ä»¶å¯ä»¥æäº¤ gitï¼ˆæ— æ•æ„Ÿä¿¡æ¯ï¼‰
- å›¢é˜Ÿæˆå‘˜å…±äº«é…ç½®
- æ›´æ¸…æ™°çš„ç»“æ„
- æ”¯æŒæ³¨é‡Š
- æ”¯æŒæœ¬åœ°è¦†ç›–ï¼ˆconfig.local.ymlï¼‰

## ğŸš€ é«˜çº§ç”¨æ³•

### å¤šç¯å¢ƒé…ç½®

```bash
# å¼€å‘ç¯å¢ƒ - ä½¿ç”¨é»˜è®¤é…ç½®
vim config.yml
# ç¼–è¾‘åŸºç¡€é…ç½®

# ä¸ªäººæœ¬åœ°é…ç½®
cp config.yml config.local.yml
# ç¼–è¾‘æœ¬åœ°è¦†ç›–é…ç½®

# ç”Ÿäº§ç¯å¢ƒï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šï¼‰
export PEGASUS_CONFIG=/etc/pegasus/config.yml
```

### åŠ¨æ€åˆ‡æ¢ Provider

```bash
# é…ç½®æ–‡ä»¶ä¸­å®šä¹‰æ‰€æœ‰ provider
# è¿è¡Œæ—¶é€šè¿‡ç¯å¢ƒå˜é‡åˆ‡æ¢
export LLM_PROVIDER=anthropic
bun run dev

# æˆ–è€…ä¸´æ—¶æµ‹è¯•
LLM_PROVIDER=ollama bun run dev
```

### å›¢é˜Ÿåä½œæœ€ä½³å®è·µ

1. **æäº¤ `config.yml`** åˆ° gitï¼ˆåŸºç¡€é…ç½®ï¼‰
2. æ¯ä¸ªæˆå‘˜åˆ›å»ºè‡ªå·±çš„ `config.local.yml`ï¼ˆæœ¬åœ°è¦†ç›–ï¼‰
3. **ä¸æäº¤** `config.local.yml` å’Œ `.env` åˆ° git
4. æ•æ„Ÿä¿¡æ¯é€šè¿‡ `.env` ç®¡ç†

**.gitignore**:
```
config.local.yml
config.local.yaml
.env
.env.local
```

## ğŸ” è°ƒè¯•é…ç½®

```bash
# æŸ¥çœ‹å½“å‰åŠ è½½çš„é…ç½®
PEGASUS_LOG_LEVEL=debug bun run dev

# æ—¥å¿—ä¼šæ˜¾ç¤ºï¼š
# INFO: loading_base_config path=config.yml
# INFO: loading_local_config_override path=config.local.yml
# INFO: merging_base_and_local_configs
# INFO: active_provider provider=openai model=gpt-4o-mini
```

## ğŸ“š å‚è€ƒ

- [é»˜è®¤é…ç½®æ–‡ä»¶](../config.yml)
- [ç¯å¢ƒå˜é‡é…ç½®](../.env.example)
- [LLM Provider é…ç½®è®¾è®¡](./llm-provider-config.md)
- [é…ç½® Schema å®šä¹‰](../src/infra/config-schema.ts)

