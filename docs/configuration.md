# Pegasus Configuration Guide

Pegasus æ”¯æŒä¸¤ç§é…ç½®æ–¹å¼ï¼š**é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰**å’Œ**ç¯å¢ƒå˜é‡**ã€‚

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰

```bash
# 1. å¤åˆ¶é…ç½®æ¨¡æ¿
cp config.example.json config.json

# 2. ç¼–è¾‘ config.json
# ä¿®æ”¹ provider å’Œå¯¹åº”çš„ apiKey

# 3. è¿è¡Œ
bun run dev
```

### æ–¹å¼ 2: ç¯å¢ƒå˜é‡

```bash
# ä»ç„¶æ”¯æŒ .env æ–‡ä»¶
cp .env.example .env
# ç¼–è¾‘ .env
bun run dev
```

## ğŸ“‹ é…ç½®æ–‡ä»¶æ ¼å¼

### config.json ç»“æ„

```json
{
  "llm": {
    "provider": "openai",
    "providers": {
      "openai": {
        "apiKey": "${OPENAI_API_KEY}",
        "model": "gpt-4o-mini",
        "baseURL": null
      },
      "anthropic": {
        "apiKey": "${ANTHROPIC_API_KEY}",
        "model": "claude-sonnet-4-20250514"
      },
      "ollama": {
        "apiKey": "dummy",
        "model": "llama3.2:latest",
        "baseURL": "http://localhost:11434/v1"
      }
    }
  }
}
```

### æ”¯æŒçš„é…ç½®æ–‡ä»¶è·¯å¾„

æŒ‰ä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾ï¼š

1. å‘½ä»¤è¡ŒæŒ‡å®š: `--config path/to/config.json`
2. `config.json` ï¼ˆå½“å‰ç›®å½•ï¼‰
3. `config.local.json` ï¼ˆæœ¬åœ°è¦†ç›–ï¼Œä¸æäº¤gitï¼‰
4. `.pegasus.json` ï¼ˆéšè—é…ç½®ï¼‰
5. ç¯å¢ƒå˜é‡ï¼ˆfallbackï¼‰

## ğŸ”‘ ç¯å¢ƒå˜é‡æ’å€¼

é…ç½®æ–‡ä»¶æ”¯æŒ `${VAR_NAME}` è¯­æ³•å¼•ç”¨ç¯å¢ƒå˜é‡ï¼š

```json
{
  "llm": {
    "providers": {
      "openai": {
        "apiKey": "${OPENAI_API_KEY}"
      }
    }
  }
}
```

è¿™æ ·ä½ å¯ä»¥ï¼š
- é…ç½®æ–‡ä»¶æäº¤åˆ° gitï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰
- æ•æ„Ÿä¿¡æ¯é€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥

## ğŸ“Š é…ç½®ä¼˜å…ˆçº§

ä»é«˜åˆ°ä½ï¼š

1. **ç¯å¢ƒå˜é‡** ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
   - `LLM_PROVIDER=anthropic` è¦†ç›–é…ç½®æ–‡ä»¶

2. **é…ç½®æ–‡ä»¶**
   - `config.json` æˆ– `config.local.json`

3. **é»˜è®¤å€¼**
   - Schema ä¸­å®šä¹‰çš„é»˜è®¤å€¼

### ç¤ºä¾‹

```json
// config.json
{
  "llm": {
    "provider": "openai",
    "providers": {
      "openai": { "model": "gpt-4o-mini" }
    }
  }
}
```

```bash
# ç¯å¢ƒå˜é‡è¦†ç›–
export LLM_PROVIDER=anthropic
export ANTHROPIC_MODEL=claude-opus-4-20250514

bun run dev
# â†’ ä½¿ç”¨ anthropic provider + claude-opus-4-20250514
```

## ğŸ¨ é…ç½®ç¤ºä¾‹

### ç¤ºä¾‹ 1: å¼€å‘ç¯å¢ƒï¼ˆå¤š providerï¼‰

```json
{
  "llm": {
    "provider": "openai",
    "providers": {
      "openai": {
        "apiKey": "${OPENAI_API_KEY}",
        "model": "gpt-4o-mini"
      },
      "anthropic": {
        "apiKey": "${ANTHROPIC_API_KEY}",
        "model": "claude-sonnet-4-20250514"
      },
      "ollama": {
        "model": "llama3.2:latest",
        "baseURL": "http://localhost:11434/v1"
      }
    }
  }
}
```

åˆ‡æ¢ providerï¼š
```bash
export LLM_PROVIDER=ollama
bun run dev
```

### ç¤ºä¾‹ 2: ç”Ÿäº§ç¯å¢ƒï¼ˆå• providerï¼‰

```json
{
  "llm": {
    "provider": "anthropic",
    "providers": {
      "anthropic": {
        "apiKey": "${ANTHROPIC_API_KEY}",
        "model": "claude-sonnet-4-20250514",
        "baseURL": null
      }
    },
    "maxConcurrentCalls": 10,
    "timeout": 180
  },
  "agent": {
    "maxActiveTasks": 20,
    "maxConcurrentTools": 5
  },
  "system": {
    "logLevel": "warn"
  }
}
```

### ç¤ºä¾‹ 3: æœ¬åœ°å¼€å‘ï¼ˆOllamaï¼‰

```json
{
  "llm": {
    "provider": "ollama",
    "providers": {
      "ollama": {
        "apiKey": "dummy",
        "model": "qwen2.5:latest",
        "baseURL": "http://localhost:11434/v1"
      }
    }
  },
  "system": {
    "logLevel": "debug"
  }
}
```

### ç¤ºä¾‹ 4: OpenAI ä»£ç†

```json
{
  "llm": {
    "provider": "openai",
    "providers": {
      "openai": {
        "apiKey": "${OPENAI_API_KEY}",
        "model": "gpt-4o",
        "baseURL": "https://your-proxy.com/v1"
      }
    }
  }
}
```

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

**é…ç½®æ–‡ä»¶ + ç¯å¢ƒå˜é‡åˆ†ç¦»**ï¼š

```json
// config.json (å¯ä»¥æäº¤ git)
{
  "llm": {
    "provider": "openai",
    "providers": {
      "openai": {
        "apiKey": "${OPENAI_API_KEY}",  // å¼•ç”¨ç¯å¢ƒå˜é‡
        "model": "gpt-4o-mini"
      }
    }
  }
}
```

```bash
# .env (ä¸æäº¤ git)
OPENAI_API_KEY=sk-proj-actual-key-here
```

### âŒ ä¸æ¨è

```json
// ä¸è¦åœ¨é…ç½®æ–‡ä»¶ä¸­ç¡¬ç¼–ç  API key
{
  "llm": {
    "providers": {
      "openai": {
        "apiKey": "sk-proj-hardcoded-key"  // âŒ ä¸è¦è¿™æ ·åš
      }
    }
  }
}
```

## ğŸ“– å®Œæ•´é…ç½®é€‰é¡¹

### LLM é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `llm.provider` | string | `"openai"` | æ´»è·ƒçš„ provider |
| `llm.providers.<name>.apiKey` | string | - | API keyï¼ˆæ”¯æŒæ’å€¼ï¼‰ |
| `llm.providers.<name>.model` | string | - | æ¨¡å‹åç§° |
| `llm.providers.<name>.baseURL` | string | null | è‡ªå®šä¹‰ API endpoint |
| `llm.maxConcurrentCalls` | number | 3 | æœ€å¤§å¹¶å‘è°ƒç”¨æ•° |
| `llm.timeout` | number | 120 | è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ |

### Agent é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `agent.maxActiveTasks` | number | 5 | æœ€å¤§æ´»è·ƒä»»åŠ¡æ•° |
| `agent.maxConcurrentTools` | number | 3 | æœ€å¤§å¹¶å‘å·¥å…·è°ƒç”¨ |
| `agent.maxCognitiveIterations` | number | 10 | æœ€å¤§è®¤çŸ¥å¾ªç¯æ¬¡æ•° |
| `agent.heartbeatInterval` | number | 60 | å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰ |

### Identity é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `identity.personaPath` | string | `"data/personas/default.json"` | Persona æ–‡ä»¶è·¯å¾„ |

### Memory é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `memory.dbPath` | string | `"data/memory.db"` | SQLite æ•°æ®åº“è·¯å¾„ |
| `memory.vectorDbPath` | string | `"data/vectors"` | å‘é‡æ•°æ®åº“è·¯å¾„ |

### System é…ç½®

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `system.logLevel` | string | `"info"` | æ—¥å¿—çº§åˆ« (debug/info/warn/error/silent) |
| `system.dataDir` | string | `"data"` | æ•°æ®ç›®å½• |

## ğŸ”„ è¿ç§»æŒ‡å—

### ä»ç¯å¢ƒå˜é‡è¿ç§»åˆ°é…ç½®æ–‡ä»¶

**ä¹‹å‰ï¼ˆ.envï¼‰**ï¼š
```bash
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o-mini
```

**ç°åœ¨ï¼ˆconfig.json + .envï¼‰**ï¼š
```json
{
  "llm": {
    "provider": "openai",
    "providers": {
      "openai": {
        "apiKey": "${OPENAI_API_KEY}",
        "model": "gpt-4o-mini"
      }
    }
  }
}
```

```bash
# .env
OPENAI_API_KEY=sk-proj-...
```

**ä¼˜åŠ¿**ï¼š
- é…ç½®æ–‡ä»¶å¯ä»¥æäº¤ gitï¼ˆæ— æ•æ„Ÿä¿¡æ¯ï¼‰
- å›¢é˜Ÿæˆå‘˜å…±äº«é…ç½®
- æ›´æ¸…æ™°çš„ç»“æ„
- æ”¯æŒæ³¨é‡Šï¼ˆJSON5/JSONCï¼‰

## ğŸš€ é«˜çº§ç”¨æ³•

### å¤šç¯å¢ƒé…ç½®

```bash
# å¼€å‘ç¯å¢ƒ
cp config.example.json config.local.json
# ç¼–è¾‘ config.local.json

# ç”Ÿäº§ç¯å¢ƒ
cp config.example.json config.production.json
# é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®š
export PEGASUS_CONFIG=config.production.json
```

### åŠ¨æ€åˆ‡æ¢ Provider

```bash
# é…ç½®æ–‡ä»¶ä¸­å®šä¹‰æ‰€æœ‰ provider
# è¿è¡Œæ—¶é€šè¿‡ç¯å¢ƒå˜é‡åˆ‡æ¢
export LLM_PROVIDER=anthropic
bun run dev

# æˆ–è€…ä¸´æ—¶æµ‹è¯•
LLM_PROVIDER=ollama bun run dev
```

### å›¢é˜Ÿåä½œ

1. **æäº¤ `config.example.json`** åˆ° git
2. æ¯ä¸ªæˆå‘˜åˆ›å»ºè‡ªå·±çš„ `config.local.json`
3. **ä¸æäº¤** `config.local.json` åˆ° git
4. æ•æ„Ÿä¿¡æ¯é€šè¿‡ `.env` ç®¡ç†

## ğŸ” è°ƒè¯•é…ç½®

```bash
# æŸ¥çœ‹å½“å‰åŠ è½½çš„é…ç½®
PEGASUS_LOG_LEVEL=debug bun run dev

# æ—¥å¿—ä¼šæ˜¾ç¤ºï¼š
# INFO: loading_config_file path=config.json
# INFO: active_provider provider=openai model=gpt-4o-mini
```

## ğŸ“š å‚è€ƒ

- [é…ç½®æ–‡ä»¶ç¤ºä¾‹](../config.example.json)
- [ç¯å¢ƒå˜é‡é…ç½®](./.env.example)
- [LLM Provider é…ç½®è®¾è®¡](./llm-provider-config.md)
