# Pegasus - Ollama 本地配置（无需 API key）

# Active provider
LLM_PROVIDER=openai-compatible

# Ollama Base URL
LLM_BASE_URL=http://localhost:11434/v1

# Model (确保已经 pull: ollama pull llama3.2)
OPENAI_MODEL=llama3.2:latest

# 可选：如果 Ollama 需要 API key（通常不需要）
# OPENAI_API_KEY=dummy

# 可选配置（已有默认值）
# PEGASUS_LOG_LEVEL=info
# IDENTITY_PERSONA_PATH=data/personas/default.json
