# ============================================
# Pegasus Configuration
# ============================================
#
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# Required: LLM_API_KEY (or provider-specific key)

# ============================================
# LLM Configuration
# ============================================

# LLM Provider (REQUIRED)
# Options: openai, anthropic, openai-compatible
# Default: openai
LLM_PROVIDER=openai

# API Key (REQUIRED for most providers)
# For OpenAI: Get from https://platform.openai.com/api-keys
# For Anthropic: Get from https://console.anthropic.com/settings/keys
# Can also use OPENAI_API_KEY or ANTHROPIC_API_KEY
LLM_API_KEY=your-api-key-here

# Model to use (REQUIRED)
# OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-sonnet-4-20250514, claude-opus-4-20250514, claude-3-5-sonnet-20241022
# Default: gpt-4o-mini (cost-effective and fast)
LLM_MODEL=gpt-4o-mini

# Base URL (OPTIONAL - for OpenAI-compatible providers)
# Use this for local models (Ollama, LM Studio, vLLM, etc.)
# Examples:
#   Ollama: http://localhost:11434/v1
#   LM Studio: http://localhost:1234/v1
#   Together AI: https://api.together.xyz/v1
# LLM_BASE_URL=http://localhost:11434/v1

# Max concurrent LLM calls (default: 3)
# LLM_MAX_CONCURRENT_CALLS=3

# LLM call timeout in seconds (default: 120)
# LLM_TIMEOUT=120

# ============================================
# Example Configurations
# ============================================

# Example 1: OpenAI (Default)
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-proj-...
# LLM_MODEL=gpt-4o-mini

# Example 2: Anthropic Claude
# LLM_PROVIDER=anthropic
# LLM_API_KEY=sk-ant-api03-...
# LLM_MODEL=claude-sonnet-4-20250514

# Example 3: Local Ollama
# LLM_PROVIDER=openai-compatible
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=llama3.2:latest
# LLM_API_KEY=dummy  # Ollama doesn't need real key

# Example 4: LM Studio
# LLM_PROVIDER=openai-compatible
# LLM_BASE_URL=http://localhost:1234/v1
# LLM_MODEL=your-model-name
# LLM_API_KEY=dummy

# ============================================
# Identity Configuration
# ============================================

# Path to persona configuration file (default: data/personas/default.json)
# IDENTITY_PERSONA_PATH=data/personas/default.json

# ============================================
# Agent Configuration
# ============================================

# Max active tasks (default: 5)
# AGENT_MAX_ACTIVE_TASKS=5

# Max concurrent tool calls (default: 3)
# AGENT_MAX_CONCURRENT_TOOLS=3

# Max cognitive loop iterations (default: 10)
# AGENT_MAX_COGNITIVE_ITERATIONS=10

# Heartbeat interval in seconds (default: 60)
# AGENT_HEARTBEAT_INTERVAL=60

# ============================================
# Memory Configuration (for M2)
# ============================================

# SQLite database path (default: data/memory.db)
# MEMORY_DB_PATH=data/memory.db

# Vector database path (default: data/vectors)
# MEMORY_VECTOR_DB_PATH=data/vectors

# ============================================
# System Configuration
# ============================================

# Log level: debug, info, warn, error, silent (default: info)
# PEGASUS_LOG_LEVEL=info

# Data directory (default: data)
# PEGASUS_DATA_DIR=data
